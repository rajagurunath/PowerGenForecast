# -*- coding: utf-8 -*-
"""Copy of powerGenForecast.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/rajagurunath/PowerGenForecast/blob/master/powerGenForecastv4_datasetA.ipynb
"""

!ls

import tensorflow as tf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
#import path
import sys

plt.style.use('seaborn-notebook')

tf.__version__,pd.__version__

from google.colab import files
uploaded = files.upload()

import io
filename='Dataset_A.xlsx'
electric_df=pd.read_excel(io.BytesIO(uploaded[filename]))

#DATA_DIR='https://github.com/rajagurunath/PowerGenForecast/blob/master/data/Dataset_A.xlsx?raw=true'
#electric_df=pd.read_excel(DATA_DIR)

electric_df.head()

electric_df.columns

datetime_col='Timestamp'
power_col='Actual_Power Generation [kW]'
windspeed_col='Wind Speed [m/s]'

electric_df.set_index(pd.to_datetime(electric_df[datetime_col]),inplace=True)

electric_df.iloc[:,:].isna().sum()

electric_df=electric_df.fillna(electric_df.mean())

"""## Ploting"""

electric_df[power_col].plot(title=power_col)
plt.show()

electric_df[windspeed_col].plot(title=windspeed_col)
plt.show()



"""# Monthwise"""

electric_df.resample('1m').sum()[windspeed_col].plot()

electric_df.resample('1m').sum()[power_col].plot()

"""# Weekly"""

electric_df.resample('1w').sum()[power_col].plot()

electric_df.resample('1w').sum()[power_col].plot()

"""# Daywise"""

electric_df.resample('1D').sum()[windspeed_col].plot()

electric_df.resample('1D').sum()[power_col].plot()

"""# Train -test Split"""

electric_df[power_col].values.reshape(1,-1)

from sklearn.preprocessing import StandardScaler,Normalizer
scalar=StandardScaler()
scaled=scalar.fit_transform(electric_df[[windspeed_col,power_col]].values)

electric_df['PowerGenScaled']=scaled[:,0]
electric_df['WindSpeedScaled']=scaled[:,1]

electric_df=electric_df.sort_index()

train=electric_df[:int(len(electric_df)*0.8)]
test=electric_df[int(len(electric_df)*0.8):]
train[power_col].plot(label='train')
test[power_col].plot(label='test')
plt.title(power_col)
plt.legend()
plt.show()

train['PowerGenScaled'].plot(label='train')
test['PowerGenScaled'].plot(label='test')
plt.title('Power Generated scaled')
plt.legend()
plt.show()

"""# Neural Networks-Model Building

## Approach 1 -Treating power Generated as Sequence
"""

#@title Train config
INP_SEQ = 96 #@param {type:raw}'

OUT_SEQ=96 #@param {type:raw}'

power=train['PowerGenScaled'].values
wind=train['WindSpeedScaled'].values

def powerG():
    inp_l=[]
    out_l=[]
    for i in range(power.shape[0]-(OUT_SEQ)):
        yield (wind[i:i+INP_SEQ].reshape(1,-1),power[i:i+OUT_SEQ].reshape(1,-1))
        
def prepare_data(W,P):
    print(W.shape)
    inp_l=[]
    out_l=[]
    for i in range(W.shape[0]-(OUT_SEQ)):
        inp_l.append(W[i:i+INP_SEQ])
        out_l.append(P[i:i+OUT_SEQ])
    X=np.array(inp_l)
    Y=np.array(out_l)
    return X,Y

X,Y=prepare_data(wind,power)

"""ludwigdf=pd.DataFrame({'inp_ts':[X],'out_ts':[Y]},index=range(len(X)))
ludwigdf.to_csv(DIR+'/ludwig_ts.csv')
"""

test[power_col][test[power_col].isna()]
test[power_col].plot()

arraytest=test['PowerGenScaled'].values
powertest=test['PowerGenScaled'].values
windtest=test['WindSpeedScaled'].values


def powerGtest(use_as_iter=True):
    if use_as_iter:
        for i in range(powertest.shape[0]-(OUT_SEQ)):
            yield (windtest[i:i+INP_SEQ].reshape(1,-1),powertest[i:i+OUT_SEQ].reshape(1,-1))
def inference():
    inp_l=[]
    out_l=[]
    for i in range(powertest.shape[0]-(OUT_SEQ)):
        inp_l.append(windtest[i:i+INP_SEQ])
        out_l.append(powertest[i:i+OUT_SEQ])
    X=np.array(inp_l)
    Y=np.array(out_l)
    return X,Y
#xt,yt=powerGtest()

dstest=tf.data.Dataset.from_generator(powerGtest,(tf.float32,tf.float32),(tf.TensorShape([1,96]),tf.TensorShape([1,96])))

ds=tf.data.Dataset.from_generator(powerG,(tf.float32,tf.float32),(tf.TensorShape([1,96]),tf.TensorShape([1,96])))

value=ds.make_one_shot_iterator().get_next()

sess=tf.Session()
sess.run(value)

class windToPower(tf.keras.Model):
    def __init__(self, outseq,num_units=192,batch_size=1):
        super().__init__()
        self.outseq = outseq
        self.batch_size=batch_size
        self.cell = tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell',num_units=num_units)
        self.dense = tf.keras.layers.Dense(units=self.outseq)

    def call(self, inputs):
        state = self.cell.zero_state(batch_size=self.batch_size, dtype=tf.float32)
        output,state=self.cell(inputs,state)
        output=self.dense(output)
        return output

lstm=windToPower(num_units=INP_SEQ,outseq=OUT_SEQ)
lstm.compile('adam',loss='mse')

lstm.summary()

TB=tf.keras.callbacks.TensorBoard('./logs2',histogram_freq=10,write_grads=True,batch_size=32,write_graph=True)
ES=tf.keras.callbacks.EarlyStopping(patience=20)
filepath = 'model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'

MC=tf.keras.callbacks.ModelCheckpoint(filepath,save_weights_only=True)
#lstm.load_weights('./lstm2.h5')
history=lstm.fit(ds,epochs=50,steps_per_epoch=500,validation_data=dstest,validation_steps=10,callbacks=[ES,MC,TB])

!ls

"""# Tensorboard visualization"""

LOG_DIR = 'logs2'
get_ipython().system_raw(
    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'
    .format(LOG_DIR)
)

! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip
! unzip ngrok-stable-linux-amd64.zip

"""***Tensorboard link ***"""

get_ipython().system_raw('./ngrok http 6006 &')
! curl -s http://localhost:4040/api/tunnels | python3 -c \
    "import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])"

plt.plot(lstm.history.history['val_loss'])
plt.title('val loss')
plt.show()

lstm.evaluate(dstest,steps=100)

predicted=lstm.predict(dstest,steps=1)

predicted.shape

"""# inference or prediction time"""

test['PowerGenScaled'].plot()

predicted=lstm.predict_on_batch(dstest)

testiter=dstest.make_one_shot_iterator()
x,y=testiter.get_next()

plt.plot(predicted.reshape(-1))
plt.plot(test['PowerGenScaled'].values)
plt.show()

xtest,ytest=inference()
#lstm.predict(X)

xtest.shape,ytest.shape,xtest[0].reshape(1,-1).shape

"""# *Prediction for last 10 days*"""

from sklearn.metrics import mean_absolute_error,mean_squared_error

predicted.shape,xtest.shape,predicted.shape,xtest[1].shape
#scalar.inverse_transform([xtest[ithday],predicted[ithday-1]])

scalar.inverse_transform(np.array([xtest[1],predicted.reshape(-1)]).reshape(96,-1))

for i in range(1,10):
  ithday=len(xtest)-96*i
  predicted=lstm.predict(xtest[ithday].reshape(1,-1))
  original=ytest[ithday]
  
  original=scalar.inverse_transform(np.array([xtest[ithday],original.reshape(-1)]).reshape(OUT_SEQ,-1))[:,1]
  predicted=scalar.inverse_transform(np.array([xtest[ithday],predicted.reshape(-1)]).reshape(OUT_SEQ,-1))[:,1]
  
  plt.plot(predicted.reshape(-1),label='predicted')
  plt.plot(original,label='original')
  mae=mean_absolute_error(original,predicted.reshape(-1))
  rmse=mean_squared_error(original,predicted.reshape(-1))**0.5
  plt.title('Day-{} : mae={} ,rmse={}'.format(i,mae,rmse))
  plt.legend()
  plt.show()

lstm_est=tf.keras.estimator.model_to_estimator(lstm)

"""# prediction for the next day

lstmestimator=tf.keras.estimator.model_to_estimator(keras_model=lstm)
"""

last_day=electric_df[datetime_col].max().date()
print(last_day)
electric_df[electric_df[datetime_col]>=last_day]

electric_df[electric_df[datetime_col]>=last_day].to_csv('last_day.csv')

last_day_df=pd.read_csv('last_day.csv')

last_day_df[windspeed_col].plot()

power_col

last_day_values=np.array([last_day_df[windspeed_col].values,
         lstm.predict(last_day_df[windspeed_col].values.reshape(1,-1)).reshape(-1)]).reshape(OUT_SEQ,-1)
scalar.inverse_transform(last_day_values)

last_day_predicted=scalar.inverse_transform(np.array([last_day_df['WindSpeedScaled'].values,
         lstm.predict(last_day_df['WindSpeedScaled'].values.reshape(1,-1)).reshape(-1)]).reshape(OUT_SEQ,-1))[:,1]
last_day_predicted.shape

plt.plot(last_day_predicted)
plt.show()

last_day_power_generated=last_day_df[power_col]
plt.plot(last_day_power_generated)
plt.show()

plt.plot(last_day_power_generated,label='power generated')
plt.plot(last_day_predicted,label='predicted')
plt.legend()
plt.show()

file_to_download='last_day.csv'
files.download(file_to_download)

last_day_df['predicted_power']=last_day_predicted
last_day_df.to_csv('last_day.csv')

